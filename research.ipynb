{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6199abb",
   "metadata": {},
   "source": [
    "Описание столбцов датасета\n",
    "\n",
    "timestamp\n",
    "Временная метка наблюдения, представленная в виде целого числа (Unix time или относительное время). Используется для упорядочивания временного ряда и анализа динамики показателей во времени.\n",
    "\n",
    "Показатели процессорной нагрузки\n",
    "\n",
    "cpu_r (CPU Rate)\n",
    "Процент загрузки центрального процессора. Отражает текущую вычислительную нагрузку на систему. Повышенные значения могут указывать на перегрузку CPU, неэффективные процессы или приближение отказа оборудования.\n",
    "\n",
    "load_1 (Load Average 1 min)\n",
    "Среднее количество процессов, находящихся в очереди на выполнение или в состоянии выполнения за последнюю 1 минуту. Характеризует краткосрочную нагрузку на систему.\n",
    "\n",
    "load_5 (Load Average 5 min)\n",
    "Среднее значение нагрузки за последние 5 минут. Используется для оценки устойчивой нагрузки на процессор и сглаживания кратковременных всплесков.\n",
    "\n",
    "load_15 (Load Average 15 min)\n",
    "Среднее количество активных процессов за последние 15 минут. Позволяет выявлять долгосрочные тенденции перегрузки системы.\n",
    "\n",
    "Показатели использования оперативной памяти\n",
    "\n",
    "mem_shmem (Shared Memory Usage)\n",
    "Объём разделяемой памяти, используемой процессами. Высокие значения могут быть связаны с активной межпроцессной коммуникацией или утечками памяти.\n",
    "\n",
    "mem_u (Memory Used)\n",
    "Объём используемой оперативной памяти. При приближении к максимальным значениям возможно снижение производительности и использование swap-памяти.\n",
    "\n",
    "mem_u_e (Effective Memory Usage)\n",
    "Эффективно используемая память с учётом кешей и буферов. Более точно отражает реальную нагрузку на память по сравнению с общим потреблением.\n",
    "\n",
    "total_mem (Total Memory)\n",
    "Общий объём оперативной памяти системы. Используется как базовый параметр для нормализации и анализа относительного потребления памяти.\n",
    "\n",
    "Показатели дисковой подсистемы\n",
    "\n",
    "disk_q (Disk Queue Length)\n",
    "Длина очереди операций ввода-вывода диска. Рост значения свидетельствует о перегрузке дисковой подсистемы и возможных задержках выполнения операций.\n",
    "\n",
    "disk_r (Disk Read Rate)\n",
    "Скорость чтения данных с диска. Высокие значения могут указывать на интенсивную работу приложений или аномальное поведение.\n",
    "\n",
    "disk_rb (Disk Read Bytes)\n",
    "Объём данных, считываемых с диска за единицу времени. Используется для оценки нагрузки на дисковую подсистему.\n",
    "\n",
    "disk_svc (Disk Service Time)\n",
    "Среднее время обслуживания дисковых операций. Увеличение показателя свидетельствует о снижении производительности диска.\n",
    "\n",
    "disk_u (Disk Utilization)\n",
    "Процент времени, в течение которого диск был занят обработкой операций. Значения, близкие к 100%, указывают на перегрузку диска.\n",
    "\n",
    "disk_w (Disk Write Rate)\n",
    "Скорость записи данных на диск. Может возрастать при интенсивной логирующей активности или сбоях приложений.\n",
    "\n",
    "disk_wa (Disk Write Await)\n",
    "Среднее время ожидания операций записи. Высокие значения свидетельствуют о проблемах с производительностью записи.\n",
    "\n",
    "disk_wb (Disk Write Bytes)\n",
    "Объём данных, записываемых на диск за единицу времени.\n",
    "\n",
    "Показатели работы swap-памяти\n",
    "\n",
    "si (Swap In)\n",
    "Количество данных, загружаемых из swap-памяти в оперативную память. Частое использование swap указывает на нехватку RAM.\n",
    "\n",
    "so (Swap Out)\n",
    "Количество данных, выгружаемых из оперативной памяти в swap. Рост показателя может предшествовать деградации производительности.\n",
    "\n",
    "Сетевые показатели (интерфейс eth1)\n",
    "\n",
    "eth1_fi (Network Input Bytes)\n",
    "Объём входящего сетевого трафика через интерфейс eth1. Может отражать как нормальную нагрузку, так и аномальную активность.\n",
    "\n",
    "eth1_fo (Network Output Bytes)\n",
    "Объём исходящего сетевого трафика через интерфейс eth1.\n",
    "\n",
    "eth1_pi (Network Input Packets)\n",
    "Количество входящих сетевых пакетов. Используется для анализа сетевой активности и выявления сетевых атак.\n",
    "\n",
    "eth1_po (Network Output Packets)\n",
    "Количество исходящих сетевых пакетов.\n",
    "\n",
    "Показатели TCP-соединений\n",
    "\n",
    "tcp_tw (TCP Time-Wait)\n",
    "Количество TCP-соединений в состоянии TIME_WAIT. Большие значения могут указывать на высокую сетевую нагрузку или некорректную работу приложений.\n",
    "\n",
    "tcp_use (TCP In Use)\n",
    "Количество активных TCP-соединений.\n",
    "\n",
    "active_opens\n",
    "Число активных TCP-соединений, инициированных сервером.\n",
    "\n",
    "passive_opens\n",
    "Число входящих TCP-соединений, принятых сервером.\n",
    "\n",
    "curr_estab (Current Established)\n",
    "Количество установленных TCP-соединений в текущий момент времени.\n",
    "\n",
    "retranseg\n",
    "Количество повторно переданных TCP-сегментов. Рост показателя указывает на потери пакетов или проблемы в сети.\n",
    "\n",
    "tcp_timeouts\n",
    "Количество тайм-аутов TCP-соединений. Часто используется как индикатор сетевых сбоев и отказов.\n",
    "\n",
    "Ошибки и служебные сетевые показатели\n",
    "\n",
    "in_errs\n",
    "Количество ошибок при приёме сетевых пакетов.\n",
    "\n",
    "in_segs\n",
    "Количество принятых TCP-сегментов.\n",
    "\n",
    "out_segs\n",
    "Количество отправленных TCP-сегментов.\n",
    "\n",
    "out_rsts\n",
    "Количество отправленных TCP-сбросов соединений (RST). Может указывать на аварийное завершение соединений.\n",
    "\n",
    "listen_overflows\n",
    "Количество переполнений очереди ожидания входящих соединений. Является критическим индикатором перегрузки сервера.\n",
    "\n",
    "Показатели UDP\n",
    "\n",
    "udp_in_dg (UDP In Datagrams)\n",
    "Количество принятых UDP-датаграмм.\n",
    "\n",
    "udp_out_dg (UDP Out Datagrams)\n",
    "Количество отправленных UDP-датаграмм.\n",
    "\n",
    "udp_rcv_buf_errs\n",
    "Ошибки приёма UDP-датаграмм из-за переполнения буфера.\n",
    "\n",
    "udp_snd_buf_errs\n",
    "Ошибки отправки UDP-датаграмм из-за переполнения буфера.\n",
    "\n",
    "Целевая переменная\n",
    "\n",
    "label\n",
    "Целевая метка состояния системы:\n",
    "\n",
    "0 — нормальное состояние\n",
    "\n",
    "1 — отказ или аномальное состояние\n",
    "\n",
    "Используется для обучения и оценки моделей прогнозирования отказов оборудования в компьютерных сетях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "aa94f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b787a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINES = [f\"machine-1-{i}.csv\" for i in range(1, 9)]\n",
    "\n",
    "HORIZON = 1\n",
    "LAGS = [5, 10, 20]\n",
    "TOP_K_FEATURES = 15\n",
    "TRAIN_RATIO = 0.7\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "75d35af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    names = [\n",
    "        'cpu_r', 'load_1', 'load_5', 'load_15', 'mem_shmem', 'mem_u', 'mem_u_e', 'total_mem',\n",
    "        'disk_q', 'disk_r', 'disk_rb', 'disk_svc', 'disk_u', 'disk_w', 'disk_wa', 'disk_wb',\n",
    "        'si', 'so', 'eth1_fi', 'eth1_fo', 'eth1_pi', 'eth1_po', 'tcp_tw', 'tcp_use',\n",
    "        'active_opens', 'curr_estab', 'in_errs', 'in_segs', 'listen_overflows', 'out_rsts',\n",
    "        'out_segs', 'passive_opens', 'retransegs', 'tcp_timeouts',\n",
    "        'udp_in_dg', 'udp_out_dg', 'udp_rcv_buf_errs', 'udp_snd_buf_errs'\n",
    "    ]\n",
    "    return df.rename(columns={f\"col_{i}\": names[i] for i in range(len(names))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d06ee098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_label_future(df: pd.DataFrame, horizon: int) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"label_future\"] = df[\"label\"].shift(-horizon)\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2b6c6a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lags(df: pd.DataFrame, lags: list[int]) -> pd.DataFrame:\n",
    "    features = [c for c in df.columns if c not in [\"label\", \"label_future\"]]\n",
    "    lag_frames = []\n",
    "\n",
    "    for lag in lags:\n",
    "        shifted = df[features].shift(lag)\n",
    "        shifted.columns = [f\"{c}_lag_{lag}\" for c in features]\n",
    "        lag_frames.append(shifted)\n",
    "\n",
    "    return pd.concat([df] + lag_frames, axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "587fa4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_machine(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, index_col=\"timestamp\")\n",
    "    df = rename_columns(df)\n",
    "    df = build_label_future(df, HORIZON)\n",
    "    df = build_lags(df, LAGS)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "62f38307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(y_true, y_pred, y_prob) -> dict:\n",
    "    return {\n",
    "        \"ROC-AUC\": roc_auc_score(y_true, y_prob),\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1-score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4ad565d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold_f1(y_true, y_prob):\n",
    "    best_t, best_f1 = 0.5, -1\n",
    "    for t in np.arange(0.05, 0.96, 0.01):\n",
    "        y_pred = (y_prob >= t).astype(int)\n",
    "        score = f1_score(y_true, y_pred, zero_division=0)\n",
    "        if score > best_f1:\n",
    "            best_f1, best_t = score, float(t)\n",
    "    return best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "568494df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] machine-1-1.csv\n",
      "[LOAD] machine-1-2.csv\n",
      "[LOAD] machine-1-3.csv\n",
      "[LOAD] machine-1-4.csv\n",
      "[LOAD] machine-1-5.csv\n",
      "[LOAD] machine-1-6.csv\n",
      "[LOAD] machine-1-7.csv\n",
      "[LOAD] machine-1-8.csv\n"
     ]
    }
   ],
   "source": [
    "train_frames = []\n",
    "test_frames = []\n",
    "\n",
    "for path in MACHINES:\n",
    "    print(f\"[LOAD] {path}\")\n",
    "    df = prepare_machine(path)\n",
    "\n",
    "    split_idx = int(len(df) * TRAIN_RATIO)\n",
    "    train_frames.append(df.iloc[:split_idx])\n",
    "    test_frames.append(df.iloc[split_idx:])\n",
    "\n",
    "df_train = pd.concat(train_frames)\n",
    "df_test  = pd.concat(test_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d7d76b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = df_train.drop(columns=[\"label\", \"label_future\"])\n",
    "y_train = df_train[\"label_future\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "63a2be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_selector = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "rf_selector.fit(X_train_full, y_train)\n",
    "\n",
    "importances = pd.Series(\n",
    "    rf_selector.feature_importances_,\n",
    "    index=X_train_full.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "top_features = importances.head(TOP_K_FEATURES).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a6c70d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_full[top_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "58afe989",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(df_test[top_features])\n",
    "y_test = df_test[\"label_future\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cec3b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"MLP (Neural Network)\": MLPClassifier(\n",
    "        hidden_layer_sizes=(64, 32),\n",
    "        activation=\"relu\",\n",
    "        early_stopping=True,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e9994ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "trained_models = {}\n",
    "best_thresholds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8bc5dea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FIT] Logistic Regression\n",
      "[FIT] Random Forest\n",
      "[FIT] Gradient Boosting\n",
      "[FIT] MLP (Neural Network)\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"[FIT] {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    best_t = find_best_threshold_f1(y_test, y_prob)\n",
    "    y_pred = (y_prob >= best_t).astype(int)\n",
    "\n",
    "    results[name] = evaluate_metrics(y_test, y_pred, y_prob)\n",
    "    trained_models[name] = model\n",
    "    best_thresholds[name] = best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ba9abde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_by_model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "eda14015",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = trained_models[\"Logistic Regression\"]\n",
    "feature_importance_by_model[\"Logistic Regression\"] = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": top_features,\n",
    "        \"importance\": np.abs(lr.coef_[0])\n",
    "    }).sort_values(\"importance\", ascending=False).head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7175651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = trained_models[\"Random Forest\"]\n",
    "feature_importance_by_model[\"Random Forest\"] = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": top_features,\n",
    "        \"importance\": rf.feature_importances_\n",
    "    }).sort_values(\"importance\", ascending=False).head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8dbfeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = trained_models[\"Gradient Boosting\"]\n",
    "feature_importance_by_model[\"Gradient Boosting\"] = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": top_features,\n",
    "        \"importance\": gb.feature_importances_\n",
    "    }).sort_values(\"importance\", ascending=False).head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "92cd292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = trained_models[\"MLP (Neural Network)\"]\n",
    "perm = permutation_importance(\n",
    "    mlp, X_test, y_test,\n",
    "    n_repeats=5,\n",
    "    random_state=RANDOM_STATE,\n",
    "    scoring=\"f1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8f870f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_by_model[\"MLP (Neural Network)\"] = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": top_features,\n",
    "        \"importance\": perm.importances_mean\n",
    "    }).sort_values(\"importance\", ascending=False).head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f7be91e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✔ Training complete. Cross-machine split applied.\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(trained_models[\"Logistic Regression\"], \"lr_model.pkl\")\n",
    "joblib.dump(trained_models[\"Random Forest\"], \"rf_model.pkl\")\n",
    "joblib.dump(trained_models[\"Gradient Boosting\"], \"gb_model.pkl\")\n",
    "joblib.dump(trained_models[\"MLP (Neural Network)\"], \"mlp_model.pkl\")\n",
    "\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(top_features, \"top_features.pkl\")\n",
    "joblib.dump(df_test, \"df_lagged_test.pkl\")\n",
    "\n",
    "joblib.dump(pd.DataFrame(results).T, \"model_comparison.pkl\")\n",
    "joblib.dump(feature_importance_by_model, \"feature_importance_by_model.pkl\")\n",
    "joblib.dump(best_thresholds, \"best_thresholds.pkl\")\n",
    "\n",
    "print(\"\\n✔ Training complete. Cross-machine split applied.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
